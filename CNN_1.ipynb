{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSPXKR_112zq"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.signal import correlate2d\n",
        "import tensorflow.keras as keras\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tkinter as tk\n",
        "from PIL import Image, ImageDraw"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Convolution on set of discrete numbers\n",
        "*   Convolution on functions\n",
        "*   Convolution on matrices\n",
        "*   Convolution vs Correlation\n",
        "*   Rectified Linear Unit(ReLU)\n",
        "*   **To find dL_dfilters** we correlate the input matrix with the matrix dL_dout\n",
        "*   Using chain rule it can be easily seen that the **dL_dbias is nothing but dL_dout**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UyiOTIU4hypL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution:\n",
        "    #define the constructor\n",
        "    def __init__(self, input_shape, filter_size, num_filters):\n",
        "        input_height, input_width = input_shape\n",
        "        self.input_shape = input_shape\n",
        "        self.num_filters = num_filters\n",
        "\n",
        "        #defining the output and filter size\n",
        "        self.filter_shape = (num_filters, filter_size, filter_size)\n",
        "        self.output_shape = (num_filters, input_height - filter_size + 1, input_width - filter_size + 1)\n",
        "\n",
        "        #initialize the filters and biases\n",
        "        self.filters = np.random.randn(*self.filter_shape)\n",
        "        self.biases = np.random.randn(*self.output_shape)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, input_data):\n",
        "        self.input_data = input_data\n",
        "\n",
        "        #initialize the output\n",
        "        output = np.zeros(self.output_shape)\n",
        "        #Apply the convolution operation\n",
        "        for i in range(self.num_filters):\n",
        "            output[i] = correlate2d(input_data, self.filters[i], mode='valid') + self.biases[i]\n",
        "        #Apply the activation function(ReLU)\n",
        "        output = np.maximum(0, output)\n",
        "        return output\n",
        "\n",
        "    #define the backward pass\n",
        "    def backward(self, dL_dout, lr):\n",
        "        '''dL_dout is the derivative of Loss wrt output of convolution layer'''\n",
        "        #initialize the matrices to store gradients\n",
        "        dL_dinput = np.zeros_like(self.input_data)\n",
        "        dL_dfilters = np.zeros_like(self.filters)\n",
        "\n",
        "        #Finding gradients wrt to input and filters\n",
        "        for i in range(self.num_filters):\n",
        "            #Calculating the gradient of loss wrt filters\n",
        "            dL_dfilters[i] = correlate2d(self.input_data, dL_dout[i], mode='valid')\n",
        "            #Calculating the gradient of loss wrt input\n",
        "            dL_dinput += correlate2d(dL_dout[i], self.filters[i], mode='full')\n",
        "\n",
        "        #Update the filters and biases\n",
        "        self.filters -= lr * dL_dfilters\n",
        "        self.biases -= lr * dL_dout\n",
        "\n",
        "        return dL_dinput"
      ],
      "metadata": {
        "id": "NCItp6mG1_vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Motive is to reduce the size of matrix and retain only the most important features.\n",
        "*   In MaxPooling, the backward pass does not involve gradient computations. Unlike other MaxPooling simply passes the maximum values to the next layer without any further computations.  \n",
        "Therefore, during the backward pass of MaxPooling, we do not calculate gradients. Instead, we transmit the maximum gradients obtained from the previous layer directly to the corresponding locations in the next layer. This process ensures that the maximum gradient values flow through the MaxPooling layer and continue propagating through the network.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PK4BVrnSm8m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool:\n",
        "    #define constructor\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, input_data):\n",
        "        self.input_data = input_data\n",
        "        #define dimensions of pooling layer\n",
        "        self.num_channels, input_height, input_width = input_data.shape\n",
        "        self.output_height = input_height // self.pool_size\n",
        "        self.output_width = input_width // self.pool_size\n",
        "        #defining the output shape\n",
        "        self.output = np.zeros((self.num_channels, self.output_height, self.output_width))\n",
        "\n",
        "        #Iterate over channels\n",
        "        for c in range(self.num_channels):\n",
        "            #Loop through height\n",
        "            for h in range(self.output_height):\n",
        "                #Loop through width\n",
        "                for w in range(self.output_width):\n",
        "                    #Apply max pooling operation\n",
        "                    self.output[c, h, w] = np.max(input_data[c, h*self.pool_size:(h+1)*self.pool_size, w*self.pool_size:(w+1)*self.pool_size])\n",
        "        return self.output\n",
        "\n",
        "    #define the backward pass\n",
        "    def backward(self, dL_dout, lr):\n",
        "        dL_dinput = np.zeros_like(self.input_data)\n",
        "        #Iterate over channels\n",
        "        for c in range(self.num_channels):\n",
        "            #Loop through height\n",
        "            for h in range(self.output_height):\n",
        "                #Loop through width\n",
        "                for w in range(self.output_width):\n",
        "                    '''mask is used to identify the maximum gradient in the gradeint matrix coming from next layer'''\n",
        "                    mask = self.input_data[c, h*self.pool_size:(h+1)*self.pool_size, w*self.pool_size:(w+1)*self.pool_size] == np.max(self.input_data[c, h*self.pool_size:(h+1)*self.pool_size, w*self.pool_size:(w+1)*self.pool_size])\n",
        "                    dL_dinput[c, h*self.pool_size:(h+1)*self.pool_size, w*self.pool_size:(w+1)*self.pool_size] = mask * dL_dout[c, h, w]\n",
        "        return dL_dinput\n"
      ],
      "metadata": {
        "id": "Y9FeaLqk2I88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This layer converts the matrix to a single vector\n",
        "*   Beyond this layer we start building the network for classification using weights.\n",
        "*   We will be using SoftMax as activation function.\n",
        "*   Shifting of data by a fixed value doens't affect the value of softmax. We do shifting to prevent overflow of data due to large exponential numbers.\n",
        "\n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "zh1MGUzarxQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Fully_Connected:\n",
        "    #define constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        #initialize weights and biases\n",
        "        self.weights = np.random.randn(output_size, self.input_size)\n",
        "        self.biases = np.random.randn(output_size,1)\n",
        "\n",
        "    #define the activation function (Softmax)\n",
        "    def softmax(self, z):\n",
        "        #shift the input values to prevent numerical instability\n",
        "        z -= np.max(z)\n",
        "        return np.exp(z) / np.sum(np.exp(z), axis=0)\n",
        "    #define the derivative of softmax\n",
        "    #This funtion returns a metrix which store all the derivatives the softmax wrt to all entries\n",
        "    def softmax_derivative(self, s):\n",
        "        return np.diagflat(s) - np.dot(s, s.T)\n",
        "\n",
        "    #Define the forward pass\n",
        "    def forward(self, input_data):\n",
        "        self.input_data = input_data\n",
        "        #Flatten the input data\n",
        "        flattened_input = input_data.flatten().reshape(-1,1)\n",
        "        #Calculate the output\n",
        "        self.z = np.dot(self.weights, flattened_input) + self.biases\n",
        "        #apply softmax\n",
        "        self.output = self.softmax(self.z)\n",
        "        return self.output\n",
        "\n",
        "    #define the backward pass\n",
        "    def backward(self, dl_out, lr):\n",
        "        #Calculate the gradient of the loss with respect to the pre-activation output\n",
        "        dL_dy = np.dot(self.softmax_derivative(self.output), dl_out)\n",
        "        #calculate the gradient of loss wrt weights\n",
        "        dL_dw = np.dot(dL_dy, self.input_data.flatten().reshape(1,-1))\n",
        "        #calculate the gradient of loss wrt biases\n",
        "        dL_db = dL_dy\n",
        "        #calculate the gradient of loss wrt input\n",
        "        dL_dinput = np.dot(self.weights.T, dL_dy)\n",
        "        dL_dinput = dL_dinput.reshape(self.input_data.shape)\n",
        "        #update the weights and biases\n",
        "        self.weights -= lr * dL_dw\n",
        "        self.biases -= lr * dL_db\n",
        "        return dL_dinput"
      ],
      "metadata": {
        "id": "Beb_ciMG2Wsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the cross entropy loss\n",
        "def cross_entropy_loss(predictions, target):\n",
        "    num_samples = 10\n",
        "\n",
        "    #adding epsilon to avoid numerical instability\n",
        "    epsilon = 1e-7\n",
        "    #limit the data into the range of epsilon and 1-epsilon to avoid instability\n",
        "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
        "    #calculate the loss\n",
        "    loss = -np.sum(target * np.log(predictions)) / num_samples\n",
        "    return loss\n",
        "#define the derivative of cross entropy loss\n",
        "def cross_entropy_loss_derivative(actual_labels, predicted_labels):\n",
        "    num_samples = actual_labels.shape[0]\n",
        "    gradient = -actual_labels/ (predicted_labels+1e-7) / num_samples\n",
        "    return gradient"
      ],
      "metadata": {
        "id": "smtmj05d2eWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function to train the model\n",
        "def train_network(X, y, conv, pool, full, lr = 0.01, epochs=200):\n",
        "    #iterate over the number of epochs\n",
        "    for epoch in range(epochs):\n",
        "        #initialize the loss and correct predictions\n",
        "        total_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "\n",
        "        #iterate over the number of samples\n",
        "        for i in range(len(X)):\n",
        "            #forward pass\n",
        "            conv_out = conv.forward(X[i])\n",
        "            pool_out = pool.forward(conv_out)\n",
        "            full_out = full.forward(pool_out)\n",
        "            loss = cross_entropy_loss(full_out.flatten(), y[i])\n",
        "            total_loss += loss\n",
        "\n",
        "            #converting the predictions to binary\n",
        "            one_hot_pred = np.zeros_like(full_out)\n",
        "            one_hot_pred[np.argmax(full_out)] = 1\n",
        "            one_hot_pred = one_hot_pred.flatten()\n",
        "\n",
        "            #getting the index of prediction\n",
        "            num_pred = np.argmax(one_hot_pred)\n",
        "            num_y = np.argmax(y[i])\n",
        "\n",
        "            #checking if the prediction is correct\n",
        "            if num_pred == num_y:\n",
        "                correct_predictions += 1\n",
        "\n",
        "            #Backward pass\n",
        "            gradient = cross_entropy_loss_derivative(y[i], full_out.flatten()).reshape((-1,1))\n",
        "            full_back = full.backward(gradient, lr)\n",
        "            pool_back = pool.backward(full_back, lr)\n",
        "            conv_back = conv.backward(pool_back, lr)\n",
        "\n",
        "        #printing the loss and accuracy\n",
        "        average_loss = total_loss / len(X)\n",
        "        accuracy = correct_predictions / len(X) *100.0\n",
        "        print(f'Epoch: {epoch}, Loss: {average_loss}, Correct Prediction: {correct_predictions}, Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "3bAL7ZDZ2kY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sample, conv, pool, full):\n",
        "    #forward pass\n",
        "    conv_out = conv.forward(input_sample)\n",
        "    pool_out = pool.forward(conv_out)\n",
        "    #Flattening\n",
        "    flattened_output = pool_out.flatten()\n",
        "    #forward pass to fully connected layer\n",
        "    prediction = full.forward(flattened_output)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "CY3n3G--2p2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "#Normalize the data\n",
        "X_train = train_images[:7000] / 255.0\n",
        "y_train = train_labels[:7000]\n",
        "X_test = test_images[7000:10000] / 255.0\n",
        "y_test = test_labels[7000:10000]\n",
        "#print the shape of X_train\n",
        "#print(X_train.shape)\n",
        "\n",
        "#Reshape the data\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "daktjwel2ucs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cde0121-6d80-4313-b1ff-cc53103336e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size_filter = int(input('Enter the filter size: '))\n",
        "num_filters = int(input('Enter the number of filters: '))\n",
        "pool_size = int(input('Enter the pool size: '))\n",
        "conv = Convolution(X_train[0].shape, size_filter, num_filters)\n",
        "pool = MaxPool(pool_size)\n",
        "full = Fully_Connected((((28-size_filter+1)//pool_size)**2)*num_filters, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPZ4sbAv3CAR",
        "outputId": "99ca4168-0f87-4202-87bb-7d9bd33eb815"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the filter size: 7\n",
            "Enter the number of filters: 1\n",
            "Enter the pool size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train the network\n",
        "print('Training the network...')\n",
        "train_network(X_train, y_train, conv, pool, full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg1pT2A33I3j",
        "outputId": "8bb29bf7-6e2f-4572-e22e-094f5d7c09d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the network...\n",
            "Epoch: 0, Loss: 0.887796745101452, Correct Prediction: 2199, Accuracy: 31.414285714285718\n",
            "Epoch: 1, Loss: 0.49448396792565813, Correct Prediction: 2482, Accuracy: 35.45714285714286\n",
            "Epoch: 2, Loss: 0.3167727293170933, Correct Prediction: 3188, Accuracy: 45.54285714285714\n",
            "Epoch: 3, Loss: 0.27324647380420575, Correct Prediction: 3861, Accuracy: 55.15714285714286\n",
            "Epoch: 4, Loss: 0.2515857868267625, Correct Prediction: 4364, Accuracy: 62.34285714285714\n",
            "Epoch: 5, Loss: 0.23868235968326257, Correct Prediction: 4660, Accuracy: 66.57142857142857\n",
            "Epoch: 6, Loss: 0.2307087591956284, Correct Prediction: 4878, Accuracy: 69.68571428571428\n",
            "Epoch: 7, Loss: 0.225267100233166, Correct Prediction: 4994, Accuracy: 71.34285714285714\n",
            "Epoch: 8, Loss: 0.22135241186906274, Correct Prediction: 5104, Accuracy: 72.91428571428571\n",
            "Epoch: 9, Loss: 0.2182266994663013, Correct Prediction: 5168, Accuracy: 73.82857142857144\n",
            "Epoch: 10, Loss: 0.2154197760744102, Correct Prediction: 5210, Accuracy: 74.42857142857143\n",
            "Epoch: 11, Loss: 0.21323684042537674, Correct Prediction: 5247, Accuracy: 74.95714285714286\n",
            "Epoch: 12, Loss: 0.2114380946651596, Correct Prediction: 5269, Accuracy: 75.27142857142857\n",
            "Epoch: 13, Loss: 0.20988912339211613, Correct Prediction: 5304, Accuracy: 75.77142857142857\n",
            "Epoch: 14, Loss: 0.20865962237967506, Correct Prediction: 5328, Accuracy: 76.11428571428571\n",
            "Epoch: 15, Loss: 0.20742400735572472, Correct Prediction: 5359, Accuracy: 76.55714285714285\n",
            "Epoch: 16, Loss: 0.20642304899037822, Correct Prediction: 5382, Accuracy: 76.88571428571429\n",
            "Epoch: 17, Loss: 0.20540363164956593, Correct Prediction: 5395, Accuracy: 77.07142857142857\n",
            "Epoch: 18, Loss: 0.20464612359952827, Correct Prediction: 5424, Accuracy: 77.4857142857143\n",
            "Epoch: 19, Loss: 0.203803512391692, Correct Prediction: 5433, Accuracy: 77.61428571428571\n",
            "Epoch: 20, Loss: 0.2031128430173455, Correct Prediction: 5448, Accuracy: 77.82857142857142\n",
            "Epoch: 21, Loss: 0.20249318097792668, Correct Prediction: 5463, Accuracy: 78.04285714285714\n",
            "Epoch: 22, Loss: 0.20181197588925082, Correct Prediction: 5475, Accuracy: 78.21428571428571\n",
            "Epoch: 23, Loss: 0.20119152765685716, Correct Prediction: 5489, Accuracy: 78.41428571428571\n",
            "Epoch: 24, Loss: 0.20063769010561722, Correct Prediction: 5497, Accuracy: 78.52857142857142\n",
            "Epoch: 25, Loss: 0.20007467330001377, Correct Prediction: 5505, Accuracy: 78.64285714285715\n",
            "Epoch: 26, Loss: 0.19960485293470145, Correct Prediction: 5518, Accuracy: 78.82857142857142\n",
            "Epoch: 27, Loss: 0.1991773567687426, Correct Prediction: 5529, Accuracy: 78.98571428571428\n",
            "Epoch: 28, Loss: 0.1986599546278952, Correct Prediction: 5540, Accuracy: 79.14285714285715\n",
            "Epoch: 29, Loss: 0.19823769251643128, Correct Prediction: 5547, Accuracy: 79.24285714285715\n",
            "Epoch: 30, Loss: 0.19785920920995761, Correct Prediction: 5552, Accuracy: 79.31428571428572\n",
            "Epoch: 31, Loss: 0.19746662017110442, Correct Prediction: 5559, Accuracy: 79.41428571428571\n",
            "Epoch: 32, Loss: 0.19715944705308142, Correct Prediction: 5566, Accuracy: 79.51428571428572\n",
            "Epoch: 33, Loss: 0.19682530594746628, Correct Prediction: 5566, Accuracy: 79.51428571428572\n",
            "Epoch: 34, Loss: 0.19650052642096255, Correct Prediction: 5573, Accuracy: 79.61428571428571\n",
            "Epoch: 35, Loss: 0.1961768612649549, Correct Prediction: 5577, Accuracy: 79.67142857142858\n",
            "Epoch: 36, Loss: 0.19592369417683683, Correct Prediction: 5588, Accuracy: 79.82857142857142\n",
            "Epoch: 37, Loss: 0.19561445045047351, Correct Prediction: 5594, Accuracy: 79.91428571428571\n",
            "Epoch: 38, Loss: 0.19533207794776175, Correct Prediction: 5601, Accuracy: 80.01428571428572\n",
            "Epoch: 39, Loss: 0.19506975977427624, Correct Prediction: 5606, Accuracy: 80.08571428571429\n",
            "Epoch: 40, Loss: 0.19478268151593173, Correct Prediction: 5611, Accuracy: 80.15714285714286\n",
            "Epoch: 41, Loss: 0.19455966781429876, Correct Prediction: 5612, Accuracy: 80.17142857142858\n",
            "Epoch: 42, Loss: 0.19427176462119386, Correct Prediction: 5609, Accuracy: 80.12857142857143\n",
            "Epoch: 43, Loss: 0.19406990015222728, Correct Prediction: 5615, Accuracy: 80.21428571428572\n",
            "Epoch: 44, Loss: 0.19386628325601307, Correct Prediction: 5619, Accuracy: 80.27142857142857\n",
            "Epoch: 45, Loss: 0.19363227280099268, Correct Prediction: 5622, Accuracy: 80.31428571428572\n",
            "Epoch: 46, Loss: 0.1933975863003127, Correct Prediction: 5628, Accuracy: 80.4\n",
            "Epoch: 47, Loss: 0.1932358291015393, Correct Prediction: 5630, Accuracy: 80.42857142857143\n",
            "Epoch: 48, Loss: 0.1930081579437693, Correct Prediction: 5633, Accuracy: 80.47142857142858\n",
            "Epoch: 49, Loss: 0.1928055695994992, Correct Prediction: 5638, Accuracy: 80.54285714285714\n",
            "Epoch: 50, Loss: 0.19265098240905, Correct Prediction: 5642, Accuracy: 80.60000000000001\n",
            "Epoch: 51, Loss: 0.19248132555263947, Correct Prediction: 5648, Accuracy: 80.68571428571428\n",
            "Epoch: 52, Loss: 0.19230924570402033, Correct Prediction: 5652, Accuracy: 80.74285714285713\n",
            "Epoch: 53, Loss: 0.19215531542018463, Correct Prediction: 5660, Accuracy: 80.85714285714286\n",
            "Epoch: 54, Loss: 0.19197668310878835, Correct Prediction: 5663, Accuracy: 80.9\n",
            "Epoch: 55, Loss: 0.1917845500369416, Correct Prediction: 5669, Accuracy: 80.98571428571428\n",
            "Epoch: 56, Loss: 0.19165998754608204, Correct Prediction: 5674, Accuracy: 81.05714285714286\n",
            "Epoch: 57, Loss: 0.19149567135469056, Correct Prediction: 5679, Accuracy: 81.12857142857143\n",
            "Epoch: 58, Loss: 0.19135477565039205, Correct Prediction: 5679, Accuracy: 81.12857142857143\n",
            "Epoch: 59, Loss: 0.19121675398870944, Correct Prediction: 5684, Accuracy: 81.2\n",
            "Epoch: 60, Loss: 0.19107179033536656, Correct Prediction: 5688, Accuracy: 81.25714285714287\n",
            "Epoch: 61, Loss: 0.19093764129158058, Correct Prediction: 5693, Accuracy: 81.32857142857142\n",
            "Epoch: 62, Loss: 0.19081081059223112, Correct Prediction: 5693, Accuracy: 81.32857142857142\n",
            "Epoch: 63, Loss: 0.19069694381835534, Correct Prediction: 5695, Accuracy: 81.35714285714286\n",
            "Epoch: 64, Loss: 0.19056649016699498, Correct Prediction: 5699, Accuracy: 81.41428571428571\n",
            "Epoch: 65, Loss: 0.19043423068492227, Correct Prediction: 5700, Accuracy: 81.42857142857143\n",
            "Epoch: 66, Loss: 0.1902810156515763, Correct Prediction: 5694, Accuracy: 81.34285714285714\n",
            "Epoch: 67, Loss: 0.19015264200920046, Correct Prediction: 5701, Accuracy: 81.44285714285714\n",
            "Epoch: 68, Loss: 0.19003095875967568, Correct Prediction: 5706, Accuracy: 81.51428571428572\n",
            "Epoch: 69, Loss: 0.18993936359464994, Correct Prediction: 5708, Accuracy: 81.54285714285714\n",
            "Epoch: 70, Loss: 0.18979800990938286, Correct Prediction: 5706, Accuracy: 81.51428571428572\n",
            "Epoch: 71, Loss: 0.18969582917078956, Correct Prediction: 5710, Accuracy: 81.57142857142857\n",
            "Epoch: 72, Loss: 0.18958231865831338, Correct Prediction: 5712, Accuracy: 81.6\n",
            "Epoch: 73, Loss: 0.18949386238691182, Correct Prediction: 5720, Accuracy: 81.71428571428572\n",
            "Epoch: 74, Loss: 0.1893791782962485, Correct Prediction: 5715, Accuracy: 81.64285714285714\n",
            "Epoch: 75, Loss: 0.18927475146499553, Correct Prediction: 5720, Accuracy: 81.71428571428572\n",
            "Epoch: 76, Loss: 0.18918701199813173, Correct Prediction: 5721, Accuracy: 81.72857142857143\n",
            "Epoch: 77, Loss: 0.18908902418207074, Correct Prediction: 5724, Accuracy: 81.77142857142857\n",
            "Epoch: 78, Loss: 0.18900447493042924, Correct Prediction: 5727, Accuracy: 81.81428571428572\n",
            "Epoch: 79, Loss: 0.18892403254388976, Correct Prediction: 5731, Accuracy: 81.87142857142857\n",
            "Epoch: 80, Loss: 0.18883100725495344, Correct Prediction: 5732, Accuracy: 81.88571428571429\n",
            "Epoch: 81, Loss: 0.18872943837040518, Correct Prediction: 5733, Accuracy: 81.89999999999999\n",
            "Epoch: 82, Loss: 0.18864330100904603, Correct Prediction: 5733, Accuracy: 81.89999999999999\n",
            "Epoch: 83, Loss: 0.18853028953156592, Correct Prediction: 5736, Accuracy: 81.94285714285714\n",
            "Epoch: 84, Loss: 0.188457228156033, Correct Prediction: 5735, Accuracy: 81.92857142857143\n",
            "Epoch: 85, Loss: 0.18836558336095444, Correct Prediction: 5736, Accuracy: 81.94285714285714\n",
            "Epoch: 86, Loss: 0.18830133641800054, Correct Prediction: 5736, Accuracy: 81.94285714285714\n",
            "Epoch: 87, Loss: 0.18822072517525404, Correct Prediction: 5739, Accuracy: 81.98571428571428\n",
            "Epoch: 88, Loss: 0.18814102996033535, Correct Prediction: 5742, Accuracy: 82.02857142857142\n",
            "Epoch: 89, Loss: 0.18807542009216288, Correct Prediction: 5745, Accuracy: 82.07142857142857\n",
            "Epoch: 90, Loss: 0.18798926113916373, Correct Prediction: 5746, Accuracy: 82.08571428571429\n",
            "Epoch: 91, Loss: 0.1879225892006154, Correct Prediction: 5747, Accuracy: 82.1\n",
            "Epoch: 92, Loss: 0.18785355236674842, Correct Prediction: 5747, Accuracy: 82.1\n",
            "Epoch: 93, Loss: 0.18777245809014612, Correct Prediction: 5748, Accuracy: 82.11428571428571\n",
            "Epoch: 94, Loss: 0.18770169354114652, Correct Prediction: 5751, Accuracy: 82.15714285714286\n",
            "Epoch: 95, Loss: 0.18762021526685727, Correct Prediction: 5752, Accuracy: 82.17142857142858\n",
            "Epoch: 96, Loss: 0.187561011834172, Correct Prediction: 5756, Accuracy: 82.22857142857143\n",
            "Epoch: 97, Loss: 0.1875162924628064, Correct Prediction: 5760, Accuracy: 82.28571428571428\n",
            "Epoch: 98, Loss: 0.1874333009571386, Correct Prediction: 5759, Accuracy: 82.27142857142857\n",
            "Epoch: 99, Loss: 0.18736468858549168, Correct Prediction: 5762, Accuracy: 82.31428571428572\n",
            "Epoch: 100, Loss: 0.1872923892295819, Correct Prediction: 5767, Accuracy: 82.38571428571429\n",
            "Epoch: 101, Loss: 0.1872104234992176, Correct Prediction: 5769, Accuracy: 82.41428571428571\n",
            "Epoch: 102, Loss: 0.1871441755135496, Correct Prediction: 5766, Accuracy: 82.37142857142857\n",
            "Epoch: 103, Loss: 0.187066184709324, Correct Prediction: 5768, Accuracy: 82.39999999999999\n",
            "Epoch: 104, Loss: 0.18701575062671516, Correct Prediction: 5768, Accuracy: 82.39999999999999\n",
            "Epoch: 105, Loss: 0.1869675083433199, Correct Prediction: 5768, Accuracy: 82.39999999999999\n",
            "Epoch: 106, Loss: 0.1868986768989447, Correct Prediction: 5766, Accuracy: 82.37142857142857\n",
            "Epoch: 107, Loss: 0.18684611113531777, Correct Prediction: 5766, Accuracy: 82.37142857142857\n",
            "Epoch: 108, Loss: 0.1867779104152128, Correct Prediction: 5768, Accuracy: 82.39999999999999\n",
            "Epoch: 109, Loss: 0.18668113219238128, Correct Prediction: 5772, Accuracy: 82.45714285714286\n",
            "Epoch: 110, Loss: 0.1866082206331964, Correct Prediction: 5768, Accuracy: 82.39999999999999\n",
            "Epoch: 111, Loss: 0.1865707617014145, Correct Prediction: 5773, Accuracy: 82.47142857142858\n",
            "Epoch: 112, Loss: 0.18648846199744, Correct Prediction: 5774, Accuracy: 82.48571428571428\n",
            "Epoch: 113, Loss: 0.18643034589315688, Correct Prediction: 5774, Accuracy: 82.48571428571428\n",
            "Epoch: 114, Loss: 0.18637368944852056, Correct Prediction: 5774, Accuracy: 82.48571428571428\n",
            "Epoch: 115, Loss: 0.1863041680191311, Correct Prediction: 5777, Accuracy: 82.52857142857142\n",
            "Epoch: 116, Loss: 0.1862255209221205, Correct Prediction: 5778, Accuracy: 82.54285714285714\n",
            "Epoch: 117, Loss: 0.1861909335823274, Correct Prediction: 5781, Accuracy: 82.58571428571429\n",
            "Epoch: 118, Loss: 0.1861043410667986, Correct Prediction: 5784, Accuracy: 82.62857142857143\n",
            "Epoch: 119, Loss: 0.1860423395412834, Correct Prediction: 5784, Accuracy: 82.62857142857143\n",
            "Epoch: 120, Loss: 0.18598235215441397, Correct Prediction: 5788, Accuracy: 82.68571428571428\n",
            "Epoch: 121, Loss: 0.18592348310972542, Correct Prediction: 5790, Accuracy: 82.71428571428572\n",
            "Epoch: 122, Loss: 0.18585985676078143, Correct Prediction: 5792, Accuracy: 82.74285714285713\n",
            "Epoch: 123, Loss: 0.18580265757628622, Correct Prediction: 5795, Accuracy: 82.78571428571428\n",
            "Epoch: 124, Loss: 0.18575489772892004, Correct Prediction: 5796, Accuracy: 82.8\n",
            "Epoch: 125, Loss: 0.18569629811481378, Correct Prediction: 5791, Accuracy: 82.72857142857143\n",
            "Epoch: 126, Loss: 0.1856368843744322, Correct Prediction: 5796, Accuracy: 82.8\n",
            "Epoch: 127, Loss: 0.18557021295646392, Correct Prediction: 5795, Accuracy: 82.78571428571428\n",
            "Epoch: 128, Loss: 0.18549966584196909, Correct Prediction: 5792, Accuracy: 82.74285714285713\n",
            "Epoch: 129, Loss: 0.185461472147579, Correct Prediction: 5792, Accuracy: 82.74285714285713\n",
            "Epoch: 130, Loss: 0.18538828866725107, Correct Prediction: 5794, Accuracy: 82.77142857142857\n",
            "Epoch: 131, Loss: 0.18532110478851846, Correct Prediction: 5792, Accuracy: 82.74285714285713\n",
            "Epoch: 132, Loss: 0.1853189284694426, Correct Prediction: 5794, Accuracy: 82.77142857142857\n",
            "Epoch: 133, Loss: 0.18523580095538014, Correct Prediction: 5797, Accuracy: 82.81428571428572\n",
            "Epoch: 134, Loss: 0.1851845057561605, Correct Prediction: 5794, Accuracy: 82.77142857142857\n",
            "Epoch: 135, Loss: 0.1851337350080673, Correct Prediction: 5796, Accuracy: 82.8\n",
            "Epoch: 136, Loss: 0.18508695564115502, Correct Prediction: 5797, Accuracy: 82.81428571428572\n",
            "Epoch: 137, Loss: 0.18509536595648063, Correct Prediction: 5795, Accuracy: 82.78571428571428\n",
            "Epoch: 138, Loss: 0.18510310840528302, Correct Prediction: 5791, Accuracy: 82.72857142857143\n",
            "Epoch: 139, Loss: 0.08349054176827213, Correct Prediction: 5861, Accuracy: 83.72857142857143\n",
            "Epoch: 140, Loss: 0.043450152140814345, Correct Prediction: 6132, Accuracy: 87.6\n",
            "Epoch: 141, Loss: 0.03875684686537683, Correct Prediction: 6240, Accuracy: 89.14285714285714\n",
            "Epoch: 142, Loss: 0.03638696285263114, Correct Prediction: 6275, Accuracy: 89.64285714285715\n",
            "Epoch: 143, Loss: 0.03491183832928396, Correct Prediction: 6307, Accuracy: 90.10000000000001\n",
            "Epoch: 144, Loss: 0.033839358973590014, Correct Prediction: 6320, Accuracy: 90.28571428571428\n",
            "Epoch: 145, Loss: 0.03305188150786338, Correct Prediction: 6339, Accuracy: 90.55714285714286\n",
            "Epoch: 146, Loss: 0.032359475607052046, Correct Prediction: 6350, Accuracy: 90.71428571428571\n",
            "Epoch: 147, Loss: 0.03188762042111438, Correct Prediction: 6366, Accuracy: 90.94285714285715\n",
            "Epoch: 148, Loss: 0.03147070143779715, Correct Prediction: 6371, Accuracy: 91.01428571428572\n",
            "Epoch: 149, Loss: 0.03110095606923734, Correct Prediction: 6378, Accuracy: 91.11428571428571\n",
            "Epoch: 150, Loss: 0.030802482789807198, Correct Prediction: 6383, Accuracy: 91.18571428571428\n",
            "Epoch: 151, Loss: 0.030501277252101045, Correct Prediction: 6388, Accuracy: 91.25714285714285\n",
            "Epoch: 152, Loss: 0.030275994094787997, Correct Prediction: 6382, Accuracy: 91.17142857142856\n",
            "Epoch: 153, Loss: 0.030087516126584814, Correct Prediction: 6382, Accuracy: 91.17142857142856\n",
            "Epoch: 154, Loss: 0.029899358194029026, Correct Prediction: 6388, Accuracy: 91.25714285714285\n",
            "Epoch: 155, Loss: 0.029729312760323576, Correct Prediction: 6398, Accuracy: 91.4\n",
            "Epoch: 156, Loss: 0.029564776208291874, Correct Prediction: 6398, Accuracy: 91.4\n",
            "Epoch: 157, Loss: 0.02941781075030234, Correct Prediction: 6400, Accuracy: 91.42857142857143\n",
            "Epoch: 158, Loss: 0.02933291148654754, Correct Prediction: 6400, Accuracy: 91.42857142857143\n",
            "Epoch: 159, Loss: 0.029219356877338867, Correct Prediction: 6401, Accuracy: 91.44285714285715\n",
            "Epoch: 160, Loss: 0.0290902228950925, Correct Prediction: 6404, Accuracy: 91.48571428571428\n",
            "Epoch: 161, Loss: 0.028991588614349847, Correct Prediction: 6402, Accuracy: 91.45714285714286\n",
            "Epoch: 162, Loss: 0.028861713658208478, Correct Prediction: 6405, Accuracy: 91.5\n",
            "Epoch: 163, Loss: 0.028758973228825122, Correct Prediction: 6409, Accuracy: 91.55714285714286\n",
            "Epoch: 164, Loss: 0.028684457520716782, Correct Prediction: 6409, Accuracy: 91.55714285714286\n",
            "Epoch: 165, Loss: 0.02862330270097175, Correct Prediction: 6411, Accuracy: 91.58571428571427\n",
            "Epoch: 166, Loss: 0.02849264936396789, Correct Prediction: 6416, Accuracy: 91.65714285714286\n",
            "Epoch: 167, Loss: 0.028385783751091895, Correct Prediction: 6416, Accuracy: 91.65714285714286\n",
            "Epoch: 168, Loss: 0.028318506289017026, Correct Prediction: 6421, Accuracy: 91.72857142857143\n",
            "Epoch: 169, Loss: 0.028232579567738773, Correct Prediction: 6419, Accuracy: 91.7\n",
            "Epoch: 170, Loss: 0.02815020989470567, Correct Prediction: 6421, Accuracy: 91.72857142857143\n",
            "Epoch: 171, Loss: 0.02806979989915711, Correct Prediction: 6423, Accuracy: 91.75714285714285\n",
            "Epoch: 172, Loss: 0.02798245950501223, Correct Prediction: 6425, Accuracy: 91.78571428571428\n",
            "Epoch: 173, Loss: 0.027932385124171018, Correct Prediction: 6426, Accuracy: 91.8\n",
            "Epoch: 174, Loss: 0.02785440457780546, Correct Prediction: 6429, Accuracy: 91.84285714285714\n",
            "Epoch: 175, Loss: 0.027773685174848343, Correct Prediction: 6432, Accuracy: 91.88571428571429\n",
            "Epoch: 176, Loss: 0.027717895397531705, Correct Prediction: 6431, Accuracy: 91.87142857142857\n",
            "Epoch: 177, Loss: 0.027664476131551086, Correct Prediction: 6433, Accuracy: 91.9\n",
            "Epoch: 178, Loss: 0.027583539457560664, Correct Prediction: 6431, Accuracy: 91.87142857142857\n",
            "Epoch: 179, Loss: 0.027533133872687323, Correct Prediction: 6432, Accuracy: 91.88571428571429\n",
            "Epoch: 180, Loss: 0.02748536075263279, Correct Prediction: 6433, Accuracy: 91.9\n",
            "Epoch: 181, Loss: 0.02740976221406052, Correct Prediction: 6432, Accuracy: 91.88571428571429\n",
            "Epoch: 182, Loss: 0.02733250480575179, Correct Prediction: 6432, Accuracy: 91.88571428571429\n",
            "Epoch: 183, Loss: 0.027299006153902895, Correct Prediction: 6432, Accuracy: 91.88571428571429\n",
            "Epoch: 184, Loss: 0.027229097623957536, Correct Prediction: 6433, Accuracy: 91.9\n",
            "Epoch: 185, Loss: 0.02717849678072169, Correct Prediction: 6433, Accuracy: 91.9\n",
            "Epoch: 186, Loss: 0.02711733519024315, Correct Prediction: 6432, Accuracy: 91.88571428571429\n",
            "Epoch: 187, Loss: 0.027036407010713248, Correct Prediction: 6441, Accuracy: 92.01428571428572\n",
            "Epoch: 188, Loss: 0.02696946324582029, Correct Prediction: 6441, Accuracy: 92.01428571428572\n",
            "Epoch: 189, Loss: 0.026942188538623933, Correct Prediction: 6439, Accuracy: 91.98571428571428\n",
            "Epoch: 190, Loss: 0.02689887092954151, Correct Prediction: 6441, Accuracy: 92.01428571428572\n",
            "Epoch: 191, Loss: 0.026839429249856783, Correct Prediction: 6443, Accuracy: 92.04285714285714\n",
            "Epoch: 192, Loss: 0.026819736301393535, Correct Prediction: 6441, Accuracy: 92.01428571428572\n",
            "Epoch: 193, Loss: 0.026790234449688536, Correct Prediction: 6448, Accuracy: 92.11428571428571\n",
            "Epoch: 194, Loss: 0.02674774240690642, Correct Prediction: 6448, Accuracy: 92.11428571428571\n",
            "Epoch: 195, Loss: 0.026699501898531132, Correct Prediction: 6449, Accuracy: 92.12857142857143\n",
            "Epoch: 196, Loss: 0.02667666206074603, Correct Prediction: 6446, Accuracy: 92.08571428571429\n",
            "Epoch: 197, Loss: 0.026663991942600166, Correct Prediction: 6449, Accuracy: 92.12857142857143\n",
            "Epoch: 198, Loss: 0.026695528121228784, Correct Prediction: 6444, Accuracy: 92.05714285714286\n",
            "Epoch: 199, Loss: 0.026637804747661302, Correct Prediction: 6449, Accuracy: 92.12857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict the output\n",
        "predictions = []\n",
        "\n",
        "for data in X_test:\n",
        "    pred = predict(data, conv, pool, full)\n",
        "    one_hot_pred = np.zeros_like(pred)\n",
        "    one_hot_pred[np.argmax(pred)] = 1\n",
        "    predictions.append(one_hot_pred.flatten())\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "#calculate the accuracy\n",
        "print(accuracy_score(y_test, predictions)*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJLX5XRF3Oko",
        "outputId": "37bfc6df-bb18-4e5f-b1af-bad127e4a30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93.10000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function to take input of image from user\n",
        "def take_input(image):\n",
        "    # Create a new 28x28 image\n",
        "    image = Image.new('RGB', (28, 28), 'white')\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Create a new Tkinter window\n",
        "    window = tk.Tk()\n",
        "\n",
        "    # Create a canvas for drawing\n",
        "    canvas = tk.Canvas(window, width=280, height=280, bg='white')\n",
        "    canvas.pack()\n",
        "\n",
        "    def draw_image(x, y):\n",
        "        # Scale the coordinates (since the canvas is 10x the size of the image)\n",
        "        x //= 10\n",
        "        y //= 10\n",
        "        # Draw on the image\n",
        "        draw.rectangle([x, y, x + 1, y + 1], fill='black')\n",
        "        # Update the canvas\n",
        "        canvas.create_rectangle(x * 10, y * 10, x * 10 + 10, y * 10 + 10, fill='black')\n",
        "\n",
        "    # Bind the drawing function to mouse motion\n",
        "    canvas.bind('<B1-Motion>', lambda event: draw_image(event.x, event.y))\n",
        "\n",
        "    def save_image():\n",
        "        # Save the image\n",
        "        image.save('drawing.png')\n",
        "\n",
        "    # Add a button to save the image\n",
        "    button = tk.Button(window, text='Save', command=save_image)\n",
        "    button.pack()\n",
        "\n",
        "    # Run the Tkinter event loop\n",
        "    window.mainloop()\n",
        "    return 'drawing.png'"
      ],
      "metadata": {
        "id": "K8ui9Ts_3dmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funtion to take image and make prediction\n",
        "def make_predictions(image):\n",
        "    #load the image\n",
        "    img = Image.open(image)\n",
        "    #img = img.resize((28, 28))\n",
        "    img = img.convert('L')\n",
        "    img = np.array(img)\n",
        "\n",
        "    #img = 255 - img\n",
        "    img = img /255.0\n",
        "    #print(img)\n",
        "    pred = predict(img, conv, pool, full)\n",
        "    one_hot_pred = np.zeros_like(pred)\n",
        "    one_hot_pred[np.argmax(pred)] = 1\n",
        "    #print(one_hot_pred)\n",
        "    print(f'Predicted label: {np.argmax(one_hot_pred)}')\n"
      ],
      "metadata": {
        "id": "zuN37reU3mNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = predict(X_test[466], conv, pool, full)\n",
        "one_hot_pred = np.zeros_like(pred)\n",
        "one_hot_pred[np.argmax(pred)] = 1\n",
        "#print(one_hot_pred)\n",
        "print(f'Predicted label: {np.argmax(one_hot_pred)}')\n",
        "print(f'Original label: {y_test[466]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjO5maB44R1P",
        "outputId": "a571f4b7-a583-45b4-bf0b-0b978f88e911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 6\n",
            "Original label: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 0.1.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOo5wGNjdTN6",
        "outputId": "914f7e4d-6c04-4239-def0-611997a0171d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 9.1.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFw5vUvsfp5i",
        "outputId": "03c66354-f1b6-4ec7-91fa-509285247980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 6.2.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRoqnHDFgPsr",
        "outputId": "0ac992d8-eb70-420d-d43f-c6cfc5221a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 0.2.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f1tocv0gs1B",
        "outputId": "2fcbddb2-01a9-4caa-90a4-62380fcc401b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 7.1.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhiZT9tx1dtu",
        "outputId": "48336161-5d18-4a63-f4d1-4bcdd9638e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 6.1.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJPCh9p52Md4",
        "outputId": "0fc2312f-3c52-46f7-a720-5c68399479a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 1.1.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZg2iGRm-gCQ",
        "outputId": "6e502681-24c2-4758-dc56-d7ac0d7cad29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 3.1.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYR_eJaW_XcC",
        "outputId": "f33873d1-e7e8-4a87-c8df-910593ed630f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 2.1.png')"
      ],
      "metadata": {
        "id": "8J8E-n-y_33z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 7.3.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-MkHR9T_58g",
        "outputId": "d3ad7525-98bc-4ef2-d78e-4f745e71e165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 9.2.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycuTsjm_A97T",
        "outputId": "ef283b5c-99e8-44c0-cb93-3a38a7379034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 9.3.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlIjU17yBQDR",
        "outputId": "1479620d-7659-4f86-8bcf-a140624c912a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 6.3.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIE7oHyDBRsB",
        "outputId": "9a3213e5-5cd2-4605-fefc-6726e5bcf64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions('/content/drive/My Drive/digit_drawing/digit 1.2.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3X0xbbsIXww",
        "outputId": "ce8da2fc-64a9-4d28-e215-e0c5202ff380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 8\n"
          ]
        }
      ]
    }
  ]
}